/*******************************************************************************
* Copyright (C) 2016-2020 Advanced Micro Devices, Inc. All rights reserved.
*
* Permission is hereby granted, free of charge, to any person obtaining a copy
* of this software and associated documentation files (the "Software"), to deal
* in the Software without restriction, including without limitation the rights
* to use, copy, modify, merge, publish, distribute, sublicense, and/or sell cop-
* ies of the Software, and to permit persons to whom the Software is furnished
* to do so, subject to the following conditions:
*
* The above copyright notice and this permission notice shall be included in all
* copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IM-
* PLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
* FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
* COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
* IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNE-
* CTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*******************************************************************************/

/**************************************************
* This file was generated by Tensile:             *
* https://github.com/ROCmSoftwarePlatform/Tensile *
**************************************************/


#include "Kernels.h"


  /******************************************/
  /* Function Prefix                        */
  /******************************************/



/* tile parameters */
#define NUM_THREADS  64
#define SG0I 8
#define SG1J 8
#define TT0I 4
#define TT1J 4
#define MT0I (SG0I*TT0I)
#define MT1J (SG1J*TT1J)
#define VECTOR_WIDTH 1
#define GLOBAL_LOAD_VECTOR_WIDTH_A 1
#define GLOBAL_LOAD_VECTOR_WIDTH_B 1
#define GLOBAL_WRITE_VECTOR_WIDTH 1

/* DepthU parameters*/
#define CPSV (NUM_THREADS / MT0I * VECTOR_WIDTH)
#define LOCAL_SPLITU 1
#define UNROLL 8
#define LOCAL_DEPTHU (LOCAL_SPLITU*UNROLL)

/* other */
#define PAD 0
#define WORK_GROUP_MAPPING 8

/* num loads parallel and perpendicular to coalesced */
#define NLCA 1
#define NLCB 1
#define NLPA 4
#define NLPB 4

/* load sizes parallel and perpendicular to coalesced */
#define LSCA (LOCAL_DEPTHU/NLCA)
#define LSPA (MT0I/NLPA)
#define LSCB (LOCAL_DEPTHU/NLCB)
#define LSPB (MT1J/NLPB)
#define LVCA (LSCA/GLOBAL_LOAD_VECTOR_WIDTH_A)
#define LVCB (LSCB/GLOBAL_LOAD_VECTOR_WIDTH_B)
#define LVPA (LSPA/GLOBAL_LOAD_VECTOR_WIDTH_A)
#define LVPB (LSPB/GLOBAL_LOAD_VECTOR_WIDTH_B)
#define LDS_OFFSET_B 256
#define LDS_NUM_ELEMENTS 512

/* global memory indices */
#define GLOBAL_D(IDX0I, IDX1J) (( (IDX0I)*strideD0I + (IDX1J)*strideD1J ))
#define GLOBAL_C(IDX0I, IDX1J) (( (IDX0I)*strideC0I + (IDX1J)*strideC1J ))
#define GLOBAL_OFFSET_A(IDXL, IDX0I, IDXK) (( (IDXL)*strideAL + (IDX0I)*strideA0I + (IDXK)*strideAK ))
#define GLOBAL_OFFSET_B(IDXL, IDX1J, IDXK) (( (IDXL)*strideBL + (IDX1J)*strideB1J + (IDXK)*strideBK ))

/* data types */
#define DATA_TYPE float
#define DEST_DATA_TYPE float
#define COMPUTE_DATA_TYPE float
#define MAGIC_DIV1(dividend, magicNumber, magicShift) ((uint64_t)(dividend) * magicNumber >> magicShift)

/* MAC's */
#define MAC(A,B,DST) DST += A*B
#define TYPE_MAC(MULA,MULB,DST) DST = MAC(MULA,MULB,DST);
#define TYPE_MAC_WRITE(DST,ALPHA,REG) DST = (ALPHA)*(REG);

/* 4x4 micro-tile */
#define MAC_4x4\
  TYPE_MAC(rA[0],rB[0],rC[0+0*TT0I]); \
  TYPE_MAC(rA[1],rB[0],rC[1+0*TT0I]); \
  TYPE_MAC(rA[2],rB[0],rC[2+0*TT0I]); \
  TYPE_MAC(rA[3],rB[0],rC[3+0*TT0I]); \
  TYPE_MAC(rA[0],rB[1],rC[0+1*TT0I]); \
  TYPE_MAC(rA[1],rB[1],rC[1+1*TT0I]); \
  TYPE_MAC(rA[2],rB[1],rC[2+1*TT0I]); \
  TYPE_MAC(rA[3],rB[1],rC[3+1*TT0I]); \
  TYPE_MAC(rA[0],rB[2],rC[0+2*TT0I]); \
  TYPE_MAC(rA[1],rB[2],rC[1+2*TT0I]); \
  TYPE_MAC(rA[2],rB[2],rC[2+2*TT0I]); \
  TYPE_MAC(rA[3],rB[2],rC[3+2*TT0I]); \
  TYPE_MAC(rA[0],rB[3],rC[0+3*TT0I]); \
  TYPE_MAC(rA[1],rB[3],rC[1+3*TT0I]); \
  TYPE_MAC(rA[2],rB[3],rC[2+3*TT0I]); \
  TYPE_MAC(rA[3],rB[3],rC[3+3*TT0I]); \

/* hard-coded initial strides CD*/
/* hard-coded initial strides AB */
#define strideD0I 1
#define strideC0I 1
#define strideAL 1
#define strideBL 1


  /******************************************/
  /* Begin Kernel                           */
  /******************************************/

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunused-parameter"
extern "C"
__global__ void Cij_Alik_Bljk_S_MT32x32x8_SE_ASEM1_K1_PSD0(
  float *D,
  float const * __restrict__ C,
  float const * __restrict__ A,
  float const * __restrict__ B,
  float const alpha,
  unsigned int const strideD1J,
  unsigned int const strideC1J,
  unsigned int const strideA0I,
  unsigned int const strideAK,
  unsigned int const strideB1J,
  unsigned int const strideBK,
  unsigned int const size0I,
  unsigned int const size1J,
  unsigned int const sizeK,
  unsigned int const sizeL,
  unsigned int staggerUIterParm,
  unsigned int problemNumGroupTiles0,
  unsigned int problemNumGroupTiles1,
  unsigned int magicNumberProblemNumGroupTiles0 )
#pragma clang diagnostic pop

 {


  /******************************************/
  /* Allocate Resources                     */
  /******************************************/

  unsigned int serial = hc_get_workitem_id(0);
  unsigned int sgId = serial / (SG0I*SG1J);
#define SCALAR_ZERO (float)(0)
#define SCALAR_OOB_DATA SCALAR_ZERO
  /* registers for MAC's */
  DEST_DATA_TYPE rC[TT0I*TT1J];
  DATA_TYPE rA[TT0I];
  DATA_TYPE rB[TT1J];

  /* registers for global->local */
  DATA_TYPE a_0_0_0_0;
  DATA_TYPE a_0_0_1_0;
  DATA_TYPE a_0_0_2_0;
  DATA_TYPE a_0_0_3_0;
  DATA_TYPE b_0_0_0_0;
  DATA_TYPE b_0_0_1_0;
  DATA_TYPE b_0_0_2_0;
  DATA_TYPE b_0_0_3_0;

  /* allocate local memory */
  __shared__ DATA_TYPE localMemory[LDS_NUM_ELEMENTS];
typedef struct MagicStruct {unsigned M; int a; int s;} MagicStruct;
const unsigned MAGIC_STRUCT_A = 0x80000000; // for extracting a-bit from shift kernarg
#define MAGIC_DIV2(dividend, magic) (((((uint64_t)(dividend) * magic.M) >> 32) + dividend*magic.a) >> magic.s)


  /******************************************/
  /* Local Read Addresses                   */
  /******************************************/


  /* local read addresses: tile assignments a */

  unsigned int lr0I = (serial % SG0I);


  /* local read addresses: tile assignments b */

  unsigned int lr1J = (serial / SG0I) % SG1J;


  /* local read addresses: final offsets a */

  unsigned int localReadOffsetA = lr0I*VECTOR_WIDTH + sgId*(MT0I+PAD);


  /* local read addresses: final offsets b */

  unsigned int localReadOffsetB = lr1J*VECTOR_WIDTH + sgId*(MT1J+PAD) + LDS_OFFSET_B;


  /* local read addresses: declare addresses a */

  DATA_TYPE *localReadA;


  /* local read addresses: declare addresses b */

  DATA_TYPE *localReadB;



  /******************************************/
  /* Begin setupNewTile                     */
  /******************************************/


  /* global read addresses: work-group */

  unsigned int wg0I = hc_get_group_id(0);
  unsigned int wg1J = hc_get_group_id(1);
  unsigned int nwg0I = hc_get_num_groups(0);
  unsigned int nwg1J = hc_get_num_groups(1);

  uint64_t wgSerial = wg0I + (wg1J % WORK_GROUP_MAPPING) * nwg0I;// within block
  unsigned int block = wg1J / WORK_GROUP_MAPPING;
  unsigned int blockRemainder = (wg1J < nwg1J-(nwg1J % WORK_GROUP_MAPPING) ) ? 0 : nwg1J % WORK_GROUP_MAPPING;
  if ( blockRemainder == 0) {
    wg0I = wgSerial / 8;
    wg1J = wgSerial % 8 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 1) {
    wg0I = wgSerial / 1;
    wg1J = wgSerial % 1 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 2) {
    wg0I = wgSerial / 2;
    wg1J = wgSerial % 2 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 3) {
    wg0I = wgSerial / 3;
    wg1J = wgSerial % 3 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 4) {
    wg0I = wgSerial / 4;
    wg1J = wgSerial % 4 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 5) {
    wg0I = wgSerial / 5;
    wg1J = wgSerial % 5 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 6) {
    wg0I = wgSerial / 6;
    wg1J = wgSerial % 6 + block*WORK_GROUP_MAPPING;
  } else {
    wg0I = wgSerial / 7;
    wg1J = wgSerial % 7 + block*WORK_GROUP_MAPPING;
  }


  /* global read addresses: tile offset assignment a */

  unsigned int globalReadOffsetA0I = (serial/LVCA) + (wg0I)*MT0I;


  /* global read addresses: tile offset assignment b */

  unsigned int globalReadOffsetB1J = (serial/LVCB) + (wg1J)*MT1J;


  /* global read addresses: unroll assignment a */

  unsigned int globalReadOffsetAL = (serial%LVCA)*GLOBAL_LOAD_VECTOR_WIDTH_A;


  /* global read addresses: unroll assignment b */

  unsigned int globalReadOffsetBL = (serial%LVCB)*GLOBAL_LOAD_VECTOR_WIDTH_B;


  /* global read addresses: other summation assignments */

#define globalReadOffsetAK 0
#define globalReadOffsetBK 0


  /* global read addresses: tile offsets a */

  unsigned int flattenedOffsetA_0_0 = globalReadOffsetA0I + 0 + 0*LSPA;
  flattenedOffsetA_0_0 = (flattenedOffsetA_0_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_0_0;
  unsigned int globalReadOffsetA0I_0_0 = flattenedOffsetA_0_0;
  unsigned int flattenedOffsetA_1_0 = globalReadOffsetA0I + 0 + 1*LSPA;
  flattenedOffsetA_1_0 = (flattenedOffsetA_1_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_1_0;
  unsigned int globalReadOffsetA0I_1_0 = flattenedOffsetA_1_0;
  unsigned int flattenedOffsetA_2_0 = globalReadOffsetA0I + 0 + 2*LSPA;
  flattenedOffsetA_2_0 = (flattenedOffsetA_2_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_2_0;
  unsigned int globalReadOffsetA0I_2_0 = flattenedOffsetA_2_0;
  unsigned int flattenedOffsetA_3_0 = globalReadOffsetA0I + 0 + 3*LSPA;
  flattenedOffsetA_3_0 = (flattenedOffsetA_3_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_3_0;
  unsigned int globalReadOffsetA0I_3_0 = flattenedOffsetA_3_0;


  /* global read addresses: tile offsets b */

  unsigned int flattenedOffsetB_0_0 = globalReadOffsetB1J + 0 + 0*LSPB;
  flattenedOffsetB_0_0 = (flattenedOffsetB_0_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_0_0;
  unsigned int globalReadOffsetB1J_0_0 = flattenedOffsetB_0_0;
  unsigned int flattenedOffsetB_1_0 = globalReadOffsetB1J + 0 + 1*LSPB;
  flattenedOffsetB_1_0 = (flattenedOffsetB_1_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_1_0;
  unsigned int globalReadOffsetB1J_1_0 = flattenedOffsetB_1_0;
  unsigned int flattenedOffsetB_2_0 = globalReadOffsetB1J + 0 + 2*LSPB;
  flattenedOffsetB_2_0 = (flattenedOffsetB_2_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_2_0;
  unsigned int globalReadOffsetB1J_2_0 = flattenedOffsetB_2_0;
  unsigned int flattenedOffsetB_3_0 = globalReadOffsetB1J + 0 + 3*LSPB;
  flattenedOffsetB_3_0 = (flattenedOffsetB_3_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_3_0;
  unsigned int globalReadOffsetB1J_3_0 = flattenedOffsetB_3_0;


  /* global read addresses: unroll offsets a */

  unsigned int globalReadOffsetAL_0_0 = globalReadOffsetAL + 0 + 0*LSCA;


  /* global read addresses: unroll offsets b */

  unsigned int globalReadOffsetBL_0_0 = globalReadOffsetBL + 0 + 0*LSCB;


  /* global read addresses: final offsets a */

  int64_t globalReadOffsetA_0_0_0_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_0_0), (globalReadOffsetAK) );
  int64_t globalReadOffsetA_0_0_1_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_1_0), (globalReadOffsetAK) );
  int64_t globalReadOffsetA_0_0_2_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_2_0), (globalReadOffsetAK) );
  int64_t globalReadOffsetA_0_0_3_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_3_0), (globalReadOffsetAK) );


  /* global read addresses: final offsets b */

  int64_t globalReadOffsetB_0_0_0_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_0_0), (globalReadOffsetBK) );
  int64_t globalReadOffsetB_0_0_1_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_1_0), (globalReadOffsetBK) );
  int64_t globalReadOffsetB_0_0_2_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_2_0), (globalReadOffsetBK) );
  int64_t globalReadOffsetB_0_0_3_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_3_0), (globalReadOffsetBK) );


  /* global read addresses: addresses a */

  DATA_TYPE const *globalReadA_0_0_0_0 = A + globalReadOffsetA_0_0_0_0;
  DATA_TYPE const *globalReadA_0_0_1_0 = A + globalReadOffsetA_0_0_1_0;
  DATA_TYPE const *globalReadA_0_0_2_0 = A + globalReadOffsetA_0_0_2_0;
  DATA_TYPE const *globalReadA_0_0_3_0 = A + globalReadOffsetA_0_0_3_0;


  /* global read addresses: addresses b */

  DATA_TYPE const *globalReadB_0_0_0_0 = B + globalReadOffsetB_0_0_0_0;
  DATA_TYPE const *globalReadB_0_0_1_0 = B + globalReadOffsetB_0_0_1_0;
  DATA_TYPE const *globalReadB_0_0_2_0 = B + globalReadOffsetB_0_0_2_0;
  DATA_TYPE const *globalReadB_0_0_3_0 = B + globalReadOffsetB_0_0_3_0;


  /* global read addresses: increments a */

  int64_t globalReadIncAL = (int64_t)strideAL*LOCAL_DEPTHU;

  int64_t globalReadIncAK = (int64_t)strideAK - strideAL*(sizeL/LOCAL_DEPTHU)*LOCAL_DEPTHU;


  /* global read addresses: increments b */

  int64_t globalReadIncBL = (int64_t)strideBL*LOCAL_DEPTHU;

  int64_t globalReadIncBK = (int64_t)strideBK - strideBL*(sizeL/LOCAL_DEPTHU)*LOCAL_DEPTHU;


  /******************************************/
  /* Local Write Addresses                  */
  /******************************************/


  /* local write addresses: tile assignment A */
  unsigned int lwA0I = (serial/LVCA);


  /* local write addresses: tile assignment B */
  unsigned int lwB1J = (serial/LVCB);


  /* local write addresses: unroll assignment A */
  unsigned int lwAL = (serial%LVCA)*GLOBAL_LOAD_VECTOR_WIDTH_A;


  /* local write addresses: unroll assignment B */
  unsigned int lwBL = (serial%LVCB)*GLOBAL_LOAD_VECTOR_WIDTH_B;


  /* local write addresses: first offset a */

  unsigned int localWriteFirstOffsetA = lwA0I + lwAL*(MT0I+PAD);


  /* local write addresses: first offset b */

  unsigned int localWriteFirstOffsetB = lwB1J + lwBL*(MT1J+PAD) + LDS_OFFSET_B;


  /* local write addresses: final offsets A */
  unsigned int localWriteOffsetA_0_0_0_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 0*LSPA);
  unsigned int localWriteOffsetA_0_0_1_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 1*LSPA);
  unsigned int localWriteOffsetA_0_0_2_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 2*LSPA);
  unsigned int localWriteOffsetA_0_0_3_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 3*LSPA);


  /* local write addresses: final offsets B */
  unsigned int localWriteOffsetB_0_0_0_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 0*LSPB);
  unsigned int localWriteOffsetB_0_0_1_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 1*LSPB);
  unsigned int localWriteOffsetB_0_0_2_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 2*LSPB);
  unsigned int localWriteOffsetB_0_0_3_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 3*LSPB);


  /* local write addresses: declare addresses A */
  DATA_TYPE *localWriteA_0_0_0_0;
  DATA_TYPE *localWriteA_0_0_1_0;
  DATA_TYPE *localWriteA_0_0_2_0;
  DATA_TYPE *localWriteA_0_0_3_0;


  /* local write addresses: declare addresses B */
  DATA_TYPE *localWriteB_0_0_0_0;
  DATA_TYPE *localWriteB_0_0_1_0;
  DATA_TYPE *localWriteB_0_0_2_0;
  DATA_TYPE *localWriteB_0_0_3_0;


  /* local write init pointers A */
  localWriteA_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_0_0);
  localWriteA_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_1_0);
  localWriteA_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_2_0);
  localWriteA_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_3_0);


  /* local write init pointers B */
  localWriteB_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_0_0);
  localWriteB_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_1_0);
  localWriteB_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_2_0);
  localWriteB_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_3_0);

  /* declare loop num iterations */

  int numIterK;
  int numIterL;


  rC[0] = SCALAR_ZERO;
  rC[1] = SCALAR_ZERO;
  rC[2] = SCALAR_ZERO;
  rC[3] = SCALAR_ZERO;
  rC[4] = SCALAR_ZERO;
  rC[5] = SCALAR_ZERO;
  rC[6] = SCALAR_ZERO;
  rC[7] = SCALAR_ZERO;
  rC[8] = SCALAR_ZERO;
  rC[9] = SCALAR_ZERO;
  rC[10] = SCALAR_ZERO;
  rC[11] = SCALAR_ZERO;
  rC[12] = SCALAR_ZERO;
  rC[13] = SCALAR_ZERO;
  rC[14] = SCALAR_ZERO;
  rC[15] = SCALAR_ZERO;


  /* summation loop 0 */


  /* Compute summation loop num iter */
  numIterK = sizeK;

  while (numIterK-- > 0) {


  /* Compute summation loop num iter */
    numIterL = sizeL / LOCAL_DEPTHU;

    /* local read addresses: init pointers a */

    localReadA = (DATA_TYPE *)(localMemory + localReadOffsetA);

    /* local read addresses: init pointers b */

    localReadB = (DATA_TYPE *)(localMemory + localReadOffsetB);


    /******************************************/
    /* End setupNewTile                       */
    /******************************************/


    /******************************************/
    /* Unrolled Loop(s) - Begin               */
    /******************************************/

    while (numIterL-- > 0) {


      /******************************************/
      /* Unroll Loop 1/1 - Begin                */
      /******************************************/



      /* global read A */
      a_0_0_0_0 = *(globalReadA_0_0_0_0 + 0);
      a_0_0_1_0 = *(globalReadA_0_0_1_0 + 0);
      a_0_0_2_0 = *(globalReadA_0_0_2_0 + 0);
      a_0_0_3_0 = *(globalReadA_0_0_3_0 + 0);

      /* global read B */
      b_0_0_0_0 = *(globalReadB_0_0_0_0 + 0);
      b_0_0_1_0 = *(globalReadB_0_0_1_0 + 0);
      b_0_0_2_0 = *(globalReadB_0_0_2_0 + 0);
      b_0_0_3_0 = *(globalReadB_0_0_3_0 + 0);

      /* global read inc A for sumL */
      globalReadA_0_0_0_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_0_0) + 1*globalReadIncAL);
      globalReadA_0_0_1_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_1_0) + 1*globalReadIncAL);
      globalReadA_0_0_2_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_2_0) + 1*globalReadIncAL);
      globalReadA_0_0_3_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_3_0) + 1*globalReadIncAL);

      /* global read inc B for sumL */
      globalReadB_0_0_0_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_0_0) + 1*globalReadIncBL);
      globalReadB_0_0_1_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_1_0) + 1*globalReadIncBL);
      globalReadB_0_0_2_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_2_0) + 1*globalReadIncBL);
      globalReadB_0_0_3_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_3_0) + 1*globalReadIncBL);


      __syncthreads(); //PGR=0, prior iter done reading lds


      /* local write a */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
      *(localWriteA_0_0_0_0 + 0) = a_0_0_0_0;
      *(localWriteA_0_0_1_0 + 0) = a_0_0_1_0;
      *(localWriteA_0_0_2_0 + 0) = a_0_0_2_0;
      *(localWriteA_0_0_3_0 + 0) = a_0_0_3_0;
#pragma clang diagnostic pop


      /* local write b */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
      *(localWriteB_0_0_0_0 + 0) = b_0_0_0_0;
      *(localWriteB_0_0_1_0 + 0) = b_0_0_1_0;
      *(localWriteB_0_0_2_0 + 0) = b_0_0_2_0;
      *(localWriteB_0_0_3_0 + 0) = b_0_0_3_0;
#pragma clang diagnostic pop


      __syncthreads(); //




      /* iter 0 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 1 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 2 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 3 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 4 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 5 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 6 */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read increment a */
      localReadA += LOCAL_SPLITU*(MT0I+PAD);

      /* local read increment b */
      localReadB += LOCAL_SPLITU*(MT1J+PAD);
      MAC_4x4


      /* iter 7 (localWrite + swap local pointers iteration) */


      /* local read a */
      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

      /* local read b */
      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

      /* local read init pointers a */
      localReadA = (DATA_TYPE *)(localMemory + localReadOffsetA);

      /* local read init pointers b */
      localReadB = (DATA_TYPE *)(localMemory + localReadOffsetB);
      MAC_4x4




      /******************************************/
      /* Unrolled Loop - End                    */
      /******************************************/

    }


    /******************************************/
    /* Tail Loop                              */
    /******************************************/


  /* Compute tail loop num iter */
    numIterL = (((sizeL % LOCAL_DEPTHU) + LOCAL_SPLITU - 1) / LOCAL_SPLITU);


    /* Update M0 for DTLDS */



    /* global read a */


    /* global read A */
    a_0_0_0_0 = ( globalReadOffsetAL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadA_0_0_0_0 + 0);
    a_0_0_1_0 = ( globalReadOffsetAL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadA_0_0_1_0 + 0);
    a_0_0_2_0 = ( globalReadOffsetAL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadA_0_0_2_0 + 0);
    a_0_0_3_0 = ( globalReadOffsetAL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadA_0_0_3_0 + 0);


    /* Update M0 for DTLDS */



    /* global read b */


    /* global read B */
    b_0_0_0_0 = ( globalReadOffsetBL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadB_0_0_0_0 + 0);
    b_0_0_1_0 = ( globalReadOffsetBL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadB_0_0_1_0 + 0);
    b_0_0_2_0 = ( globalReadOffsetBL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadB_0_0_2_0 + 0);
    b_0_0_3_0 = ( globalReadOffsetBL_0_0 + 0 >= (sizeL % LOCAL_DEPTHU) ) ? SCALAR_OOB_DATA : *(globalReadB_0_0_3_0 + 0);


    __syncthreads(); //


    /* local write init pointers A */
    localWriteA_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_0_0);
    localWriteA_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_1_0);
    localWriteA_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_2_0);
    localWriteA_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_3_0);


    /* local write init pointers B */
    localWriteB_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_0_0);
    localWriteB_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_1_0);
    localWriteB_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_2_0);
    localWriteB_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_3_0);


    /* local write a */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteA_0_0_0_0 + 0) = a_0_0_0_0;
    *(localWriteA_0_0_1_0 + 0) = a_0_0_1_0;
    *(localWriteA_0_0_2_0 + 0) = a_0_0_2_0;
    *(localWriteA_0_0_3_0 + 0) = a_0_0_3_0;
#pragma clang diagnostic pop


    /* local write b */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteB_0_0_0_0 + 0) = b_0_0_0_0;
    *(localWriteB_0_0_1_0 + 0) = b_0_0_1_0;
    *(localWriteB_0_0_2_0 + 0) = b_0_0_2_0;
    *(localWriteB_0_0_3_0 + 0) = b_0_0_3_0;
#pragma clang diagnostic pop


    __syncthreads(); //


    /* tail loop: macs */

    while (numIterL-- > 0) {


      /* local read a */

      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 


      /* local read b */

      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 


      /* local read inc a */

      localReadA += LOCAL_SPLITU*(MT0I+PAD);


      /* local read inc b */

      localReadB += LOCAL_SPLITU*(MT1J+PAD);


      MAC_4x4

    }


    /* global read inc AB */


    /* global read inc A for sumK */
    globalReadA_0_0_0_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_0_0) + 1*globalReadIncAK);
    globalReadA_0_0_1_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_1_0) + 1*globalReadIncAK);
    globalReadA_0_0_2_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_2_0) + 1*globalReadIncAK);
    globalReadA_0_0_3_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadA_0_0_3_0) + 1*globalReadIncAK);

    /* global read inc B for sumK */
    globalReadB_0_0_0_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_0_0) + 1*globalReadIncBK);
    globalReadB_0_0_1_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_1_0) + 1*globalReadIncBK);
    globalReadB_0_0_2_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_2_0) + 1*globalReadIncBK);
    globalReadB_0_0_3_0 = (DATA_TYPE const *)( ((DATA_TYPE const *)globalReadB_0_0_3_0) + 1*globalReadIncBK);

  }





  /* not-LocalSplitU: global write indices */

  unsigned int flattenedGlobalC0 = (wg0I)*MT0I + (serial % SG0I)*VECTOR_WIDTH;
  unsigned int flattenedGlobalC1 = (wg1J)*MT1J + (serial / SG0I)*VECTOR_WIDTH;
  unsigned int globalC0I = flattenedGlobalC0;
  unsigned int globalC1J = flattenedGlobalC1;


  /* not-LocalSplitU: global write */


  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }


}

#undef UNROLL
#undef LOCAL_SPLITU
#undef LOCAL_DEPTHU
#undef SG0I
#undef SG1J
#undef TT0I
#undef TT1J
#undef MT0I
#undef MT1J
#undef NLCA
#undef NLCB
#undef NLPA
#undef NLPB
#undef LSCA
#undef LSPA
#undef LSCB
#undef LSPB
#undef GLOBAL_C
#undef GLOBAL_OFFSET_A
#undef GLOBAL_OFFSET_B
#undef DATA_TYPE
#undef DEST_DATA_TYPE
#undef COMPUTE_DATA_TYPE
#undef LDS_OFFSET_B
#undef LDS_OFFSET_BLK
#undef LDS_NUM_ELEMENTS
#undef NUM_THREADS
#undef WORK_GROUP_MAPPING
#undef VECTOR_WIDTH
#undef GLOBAL_LOAD_VECTOR_WIDTH_A
#undef GLOBAL_LOAD_VECTOR_WIDTH_B
#undef GLOBAL_WRITE_VECTOR_WIDTH
#undef MAC
#undef TYPE_MAC
#undef TYPE_MAC_WRITE
#undef GLOBAL_SPLITU
#undef SCALAR_ZERO
#undef SCALAR_OOB_DATA
#undef MAC_4x4
#undef strideD0I
#undef strideC0I
#undef strideAL
#undef strideBL
#undef globalReadOffsetAK
#undef globalReadOffsetBK






  /******************************************/
  /* Function Prefix                        */
  /******************************************/



/* tile parameters */
#define NUM_THREADS  64
#define SG0I 8
#define SG1J 8
#define TT0I 4
#define TT1J 4
#define MT0I (SG0I*TT0I)
#define MT1J (SG1J*TT1J)
#define VECTOR_WIDTH 1
#define GLOBAL_LOAD_VECTOR_WIDTH_A 1
#define GLOBAL_LOAD_VECTOR_WIDTH_B 1
#define GLOBAL_WRITE_VECTOR_WIDTH 1

/* DepthU parameters*/
#define CPSV (NUM_THREADS / MT0I * VECTOR_WIDTH)
#define LOCAL_SPLITU 1
#define UNROLL 8
#define LOCAL_DEPTHU (LOCAL_SPLITU*UNROLL)

/* other */
#define PAD 0
#define WORK_GROUP_MAPPING 8

/* num loads parallel and perpendicular to coalesced */
#define NLCA 1
#define NLCB 1
#define NLPA 4
#define NLPB 4

/* load sizes parallel and perpendicular to coalesced */
#define LSCA (LOCAL_DEPTHU/NLCA)
#define LSPA (MT0I/NLPA)
#define LSCB (LOCAL_DEPTHU/NLCB)
#define LSPB (MT1J/NLPB)
#define LVCA (LSCA/GLOBAL_LOAD_VECTOR_WIDTH_A)
#define LVCB (LSCB/GLOBAL_LOAD_VECTOR_WIDTH_B)
#define LVPA (LSPA/GLOBAL_LOAD_VECTOR_WIDTH_A)
#define LVPB (LSPB/GLOBAL_LOAD_VECTOR_WIDTH_B)
#define LDS_OFFSET_B 256
#define LDS_NUM_ELEMENTS 512

/* global memory indices */
#define GLOBAL_D(IDX0I, IDX1J) (( (IDX0I)*strideD0I + (IDX1J)*strideD1J ))
#define GLOBAL_C(IDX0I, IDX1J) (( (IDX0I)*strideC0I + (IDX1J)*strideC1J ))
#define GLOBAL_OFFSET_A(IDXL, IDX0I, IDXK) (( (IDXL)*strideAL + (IDX0I)*strideA0I + (IDXK)*strideAK ))
#define GLOBAL_OFFSET_B(IDXL, IDX1J, IDXK) (( (IDXL)*strideBL + (IDX1J)*strideB1J + (IDXK)*strideBK ))

/* data types */
#define DATA_TYPE float
#define DEST_DATA_TYPE float
#define COMPUTE_DATA_TYPE float
#define MAGIC_DIV1(dividend, magicNumber, magicShift) ((uint64_t)(dividend) * magicNumber >> magicShift)

/* MAC's */
#define MAC(A,B,DST) DST += A*B
#define TYPE_MAC(MULA,MULB,DST) DST = MAC(MULA,MULB,DST);
#define TYPE_MAC_WRITE(DST,ALPHA,REG) DST = (ALPHA)*(REG);

/* 4x4 micro-tile */
#define MAC_4x4\
  TYPE_MAC(rA[0],rB[0],rC[0+0*TT0I]); \
  TYPE_MAC(rA[1],rB[0],rC[1+0*TT0I]); \
  TYPE_MAC(rA[2],rB[0],rC[2+0*TT0I]); \
  TYPE_MAC(rA[3],rB[0],rC[3+0*TT0I]); \
  TYPE_MAC(rA[0],rB[1],rC[0+1*TT0I]); \
  TYPE_MAC(rA[1],rB[1],rC[1+1*TT0I]); \
  TYPE_MAC(rA[2],rB[1],rC[2+1*TT0I]); \
  TYPE_MAC(rA[3],rB[1],rC[3+1*TT0I]); \
  TYPE_MAC(rA[0],rB[2],rC[0+2*TT0I]); \
  TYPE_MAC(rA[1],rB[2],rC[1+2*TT0I]); \
  TYPE_MAC(rA[2],rB[2],rC[2+2*TT0I]); \
  TYPE_MAC(rA[3],rB[2],rC[3+2*TT0I]); \
  TYPE_MAC(rA[0],rB[3],rC[0+3*TT0I]); \
  TYPE_MAC(rA[1],rB[3],rC[1+3*TT0I]); \
  TYPE_MAC(rA[2],rB[3],rC[2+3*TT0I]); \
  TYPE_MAC(rA[3],rB[3],rC[3+3*TT0I]); \

/* hard-coded initial strides CD*/
/* hard-coded initial strides AB */
#define strideD0I 1
#define strideC0I 1
#define strideAL 1
#define strideBL 1


  /******************************************/
  /* Begin Kernel                           */
  /******************************************/

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunused-parameter"
extern "C"
__global__ void Cij_Alik_Bljk_S_MT32x32x8_SE_ASEM8_K1_PSD1(
  float *D,
  float const * __restrict__ C,
  float const * __restrict__ A,
  float const * __restrict__ B,
  float const alpha,
  unsigned int const strideD1J,
  unsigned int const strideC1J,
  unsigned int const strideA0I,
  unsigned int const strideAK,
  unsigned int const strideB1J,
  unsigned int const strideBK,
  unsigned int const size0I,
  unsigned int const size1J,
  unsigned int const sizeK,
  unsigned int const sizeL,
  unsigned magicNumberNumIterL /*PSD*/,
  unsigned magicShiftNumIterL /*PSD*/,
  unsigned int staggerUIterParm,
  unsigned int problemNumGroupTiles0,
  unsigned int problemNumGroupTiles1,
  unsigned int magicNumberProblemNumGroupTiles0 )
#pragma clang diagnostic pop

 {


  /******************************************/
  /* Allocate Resources                     */
  /******************************************/

  unsigned int serial = hc_get_workitem_id(0);
  unsigned int sgId = serial / (SG0I*SG1J);
#define SCALAR_ZERO (float)(0)
#define SCALAR_OOB_DATA SCALAR_ZERO
  /* registers for MAC's */
  DEST_DATA_TYPE rC[TT0I*TT1J];
  DATA_TYPE rA[TT0I];
  DATA_TYPE rB[TT1J];

  /* registers for global->local */
  DATA_TYPE a_0_0_0_0;
  DATA_TYPE a_0_0_1_0;
  DATA_TYPE a_0_0_2_0;
  DATA_TYPE a_0_0_3_0;
  DATA_TYPE b_0_0_0_0;
  DATA_TYPE b_0_0_1_0;
  DATA_TYPE b_0_0_2_0;
  DATA_TYPE b_0_0_3_0;

  /* allocate local memory */
  __shared__ DATA_TYPE localMemory[LDS_NUM_ELEMENTS];
typedef struct MagicStruct {unsigned M; int a; int s;} MagicStruct;
const unsigned MAGIC_STRUCT_A = 0x80000000; // for extracting a-bit from shift kernarg
#define MAGIC_DIV2(dividend, magic) (((((uint64_t)(dividend) * magic.M) >> 32) + dividend*magic.a) >> magic.s)

  MagicStruct magicStructL;
  magicStructL.M = magicNumberNumIterL;
  magicStructL.a = (magicShiftNumIterL & MAGIC_STRUCT_A) ? 1:0;
  magicStructL.s = magicShiftNumIterL & (~MAGIC_STRUCT_A);


  /******************************************/
  /* Local Read Addresses                   */
  /******************************************/


  /* local read addresses: tile assignments a */

  unsigned int lr0I = (serial % SG0I);


  /* local read addresses: tile assignments b */

  unsigned int lr1J = (serial / SG0I) % SG1J;


  /* local read addresses: final offsets a */

  unsigned int localReadOffsetA = lr0I*VECTOR_WIDTH + sgId*(MT0I+PAD);


  /* local read addresses: final offsets b */

  unsigned int localReadOffsetB = lr1J*VECTOR_WIDTH + sgId*(MT1J+PAD) + LDS_OFFSET_B;


  /* local read addresses: declare addresses a */

  DATA_TYPE *localReadA;


  /* local read addresses: declare addresses b */

  DATA_TYPE *localReadB;



  /******************************************/
  /* Begin setupNewTile                     */
  /******************************************/


  /* global read addresses: work-group */

  unsigned int wg0I = hc_get_group_id(0);
  unsigned int wg1J = hc_get_group_id(1);
  unsigned int nwg0I = hc_get_num_groups(0);
  unsigned int nwg1J = hc_get_num_groups(1);

  uint64_t wgSerial = wg0I + (wg1J % WORK_GROUP_MAPPING) * nwg0I;// within block
  unsigned int block = wg1J / WORK_GROUP_MAPPING;
  unsigned int blockRemainder = (wg1J < nwg1J-(nwg1J % WORK_GROUP_MAPPING) ) ? 0 : nwg1J % WORK_GROUP_MAPPING;
  if ( blockRemainder == 0) {
    wg0I = wgSerial / 8;
    wg1J = wgSerial % 8 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 1) {
    wg0I = wgSerial / 1;
    wg1J = wgSerial % 1 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 2) {
    wg0I = wgSerial / 2;
    wg1J = wgSerial % 2 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 3) {
    wg0I = wgSerial / 3;
    wg1J = wgSerial % 3 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 4) {
    wg0I = wgSerial / 4;
    wg1J = wgSerial % 4 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 5) {
    wg0I = wgSerial / 5;
    wg1J = wgSerial % 5 + block*WORK_GROUP_MAPPING;
  } else if ( blockRemainder == 6) {
    wg0I = wgSerial / 6;
    wg1J = wgSerial % 6 + block*WORK_GROUP_MAPPING;
  } else {
    wg0I = wgSerial / 7;
    wg1J = wgSerial % 7 + block*WORK_GROUP_MAPPING;
  }


  /* global read addresses: tile offset assignment a */

  unsigned int globalReadOffsetA0I = (serial/LVCA) + (wg0I)*MT0I;


  /* global read addresses: tile offset assignment b */

  unsigned int globalReadOffsetB1J = (serial/LVCB) + (wg1J)*MT1J;


  /* global read addresses: unroll assignment a */

  unsigned int globalReadOffsetA = (serial%LVCA)*GLOBAL_LOAD_VECTOR_WIDTH_A;


  /* global read addresses: unroll assignment b */

  unsigned int globalReadOffsetB = (serial%LVCB)*GLOBAL_LOAD_VECTOR_WIDTH_B;


  /* global read addresses: other summation assignments */


  /* global read addresses: tile offsets a */

  unsigned int flattenedOffsetA_0_0 = globalReadOffsetA0I + 0 + 0*LSPA;
  flattenedOffsetA_0_0 = (flattenedOffsetA_0_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_0_0;
  unsigned int globalReadOffsetA0I_0_0 = flattenedOffsetA_0_0;
  unsigned int flattenedOffsetA_1_0 = globalReadOffsetA0I + 0 + 1*LSPA;
  flattenedOffsetA_1_0 = (flattenedOffsetA_1_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_1_0;
  unsigned int globalReadOffsetA0I_1_0 = flattenedOffsetA_1_0;
  unsigned int flattenedOffsetA_2_0 = globalReadOffsetA0I + 0 + 2*LSPA;
  flattenedOffsetA_2_0 = (flattenedOffsetA_2_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_2_0;
  unsigned int globalReadOffsetA0I_2_0 = flattenedOffsetA_2_0;
  unsigned int flattenedOffsetA_3_0 = globalReadOffsetA0I + 0 + 3*LSPA;
  flattenedOffsetA_3_0 = (flattenedOffsetA_3_0 > (size0I-1)) ? (size0I-1):flattenedOffsetA_3_0;
  unsigned int globalReadOffsetA0I_3_0 = flattenedOffsetA_3_0;


  /* global read addresses: tile offsets b */

  unsigned int flattenedOffsetB_0_0 = globalReadOffsetB1J + 0 + 0*LSPB;
  flattenedOffsetB_0_0 = (flattenedOffsetB_0_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_0_0;
  unsigned int globalReadOffsetB1J_0_0 = flattenedOffsetB_0_0;
  unsigned int flattenedOffsetB_1_0 = globalReadOffsetB1J + 0 + 1*LSPB;
  flattenedOffsetB_1_0 = (flattenedOffsetB_1_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_1_0;
  unsigned int globalReadOffsetB1J_1_0 = flattenedOffsetB_1_0;
  unsigned int flattenedOffsetB_2_0 = globalReadOffsetB1J + 0 + 2*LSPB;
  flattenedOffsetB_2_0 = (flattenedOffsetB_2_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_2_0;
  unsigned int globalReadOffsetB1J_2_0 = flattenedOffsetB_2_0;
  unsigned int flattenedOffsetB_3_0 = globalReadOffsetB1J + 0 + 3*LSPB;
  flattenedOffsetB_3_0 = (flattenedOffsetB_3_0 > (size1J-1)) ? (size1J-1):flattenedOffsetB_3_0;
  unsigned int globalReadOffsetB1J_3_0 = flattenedOffsetB_3_0;

  /* global read addresses: addresses a */

  DATA_TYPE const *globalReadA_0_0_0_0;
  DATA_TYPE const *globalReadA_0_0_1_0;
  DATA_TYPE const *globalReadA_0_0_2_0;
  DATA_TYPE const *globalReadA_0_0_3_0;


  /* global read addresses: addresses b */

  DATA_TYPE const *globalReadB_0_0_0_0;
  DATA_TYPE const *globalReadB_0_0_1_0;
  DATA_TYPE const *globalReadB_0_0_2_0;
  DATA_TYPE const *globalReadB_0_0_3_0;


  /******************************************/
  /* Local Write Addresses                  */
  /******************************************/


  /* local write addresses: tile assignment A */
  unsigned int lwA0I = (serial/LVCA);


  /* local write addresses: tile assignment B */
  unsigned int lwB1J = (serial/LVCB);


  /* local write addresses: unroll assignment A */
  unsigned int lwAL = (serial%LVCA)*GLOBAL_LOAD_VECTOR_WIDTH_A;


  /* local write addresses: unroll assignment B */
  unsigned int lwBL = (serial%LVCB)*GLOBAL_LOAD_VECTOR_WIDTH_B;


  /* local write addresses: first offset a */

  unsigned int localWriteFirstOffsetA = lwA0I + lwAL*(MT0I+PAD);


  /* local write addresses: first offset b */

  unsigned int localWriteFirstOffsetB = lwB1J + lwBL*(MT1J+PAD) + LDS_OFFSET_B;


  /* local write addresses: final offsets A */
  unsigned int localWriteOffsetA_0_0_0_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 0*LSPA);
  unsigned int localWriteOffsetA_0_0_1_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 1*LSPA);
  unsigned int localWriteOffsetA_0_0_2_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 2*LSPA);
  unsigned int localWriteOffsetA_0_0_3_0 = localWriteFirstOffsetA + (0 + 0*LSCA)*(MT0I+PAD) + (0 + 3*LSPA);


  /* local write addresses: final offsets B */
  unsigned int localWriteOffsetB_0_0_0_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 0*LSPB);
  unsigned int localWriteOffsetB_0_0_1_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 1*LSPB);
  unsigned int localWriteOffsetB_0_0_2_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 2*LSPB);
  unsigned int localWriteOffsetB_0_0_3_0 = localWriteFirstOffsetB + (0 + 0*LSCB)*(MT1J+PAD) + (0 + 3*LSPB);


  /* local write addresses: declare addresses A */
  DATA_TYPE *localWriteA_0_0_0_0;
  DATA_TYPE *localWriteA_0_0_1_0;
  DATA_TYPE *localWriteA_0_0_2_0;
  DATA_TYPE *localWriteA_0_0_3_0;


  /* local write addresses: declare addresses B */
  DATA_TYPE *localWriteB_0_0_0_0;
  DATA_TYPE *localWriteB_0_0_1_0;
  DATA_TYPE *localWriteB_0_0_2_0;
  DATA_TYPE *localWriteB_0_0_3_0;


  /* local write init pointers A */
  localWriteA_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_0_0);
  localWriteA_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_1_0);
  localWriteA_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_2_0);
  localWriteA_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_3_0);


  /* local write init pointers B */
  localWriteB_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_0_0);
  localWriteB_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_1_0);
  localWriteB_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_2_0);
  localWriteB_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_3_0);

  /* declare loop num iterations */

  int numIterK;
  int numIterL;


  rC[0] = SCALAR_ZERO;
  rC[1] = SCALAR_ZERO;
  rC[2] = SCALAR_ZERO;
  rC[3] = SCALAR_ZERO;
  rC[4] = SCALAR_ZERO;
  rC[5] = SCALAR_ZERO;
  rC[6] = SCALAR_ZERO;
  rC[7] = SCALAR_ZERO;
  rC[8] = SCALAR_ZERO;
  rC[9] = SCALAR_ZERO;
  rC[10] = SCALAR_ZERO;
  rC[11] = SCALAR_ZERO;
  rC[12] = SCALAR_ZERO;
  rC[13] = SCALAR_ZERO;
  rC[14] = SCALAR_ZERO;
  rC[15] = SCALAR_ZERO;


  /* summation loop 0 */


  /* Compute summation loop num iter */
  numIterK = sizeK;


  /* Compute summation loop num iter */
  numIterL = sizeL;
  unsigned int psdIter=0; // packed summation dim iterator

  /* local read addresses: init pointers a */

  localReadA = (DATA_TYPE *)(localMemory + localReadOffsetA);

  /* local read addresses: init pointers b */

  localReadB = (DATA_TYPE *)(localMemory + localReadOffsetB);


  /******************************************/
  /* End setupNewTile                       */
  /******************************************/


  /******************************************/
  /* Unrolled Loop(s) - Begin               */
  /******************************************/

  while (psdIter + LOCAL_DEPTHU <= (numIterK*numIterL)) {

    /******************************************/
    /* Unroll Loop 1/1 - Begin                */
    /******************************************/

    /* global read addresses: unroll offsets a */
    unsigned int globalReadOffsetA_0_0 = globalReadOffsetA + 0 + 0*LSCA + psdIter;

    /* global read addresses: unroll offsets b */
    unsigned int globalReadOffsetB_0_0 = globalReadOffsetB + 0 + 0*LSCB + psdIter;

    unsigned int tmpBits = 0;
    tmpBits = MAGIC_DIV2((globalReadOffsetA_0_0), magicStructL);
    unsigned int globalReadOffsetAL_0_0 = (globalReadOffsetA_0_0) - tmpBits*numIterL;
    unsigned int psdPackedBits = 0;
    psdPackedBits = tmpBits;

    unsigned int globalReadOffsetAK_0_0 = psdPackedBits;

    tmpBits = MAGIC_DIV2((globalReadOffsetB_0_0), magicStructL);
    unsigned int globalReadOffsetBL_0_0 = (globalReadOffsetB_0_0) - tmpBits*numIterL;
    psdPackedBits = tmpBits;
    unsigned int globalReadOffsetBK_0_0 = psdPackedBits;

    /* global read addresses: final offsets a */
    int64_t globalReadOffsetA_0_0_0_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_0_0), (globalReadOffsetAK_0_0) );
    int64_t globalReadOffsetA_0_0_1_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_1_0), (globalReadOffsetAK_0_0) );
    int64_t globalReadOffsetA_0_0_2_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_2_0), (globalReadOffsetAK_0_0) );
    int64_t globalReadOffsetA_0_0_3_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_3_0), (globalReadOffsetAK_0_0) );

    /* global read addresses: final offsets b */
    int64_t globalReadOffsetB_0_0_0_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_0_0), (globalReadOffsetBK_0_0) );
    int64_t globalReadOffsetB_0_0_1_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_1_0), (globalReadOffsetBK_0_0) );
    int64_t globalReadOffsetB_0_0_2_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_2_0), (globalReadOffsetBK_0_0) );
    int64_t globalReadOffsetB_0_0_3_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_3_0), (globalReadOffsetBK_0_0) );

    /* global read inc A from base */
    globalReadA_0_0_0_0 = A + globalReadOffsetA_0_0_0_0;
    globalReadA_0_0_1_0 = A + globalReadOffsetA_0_0_1_0;
    globalReadA_0_0_2_0 = A + globalReadOffsetA_0_0_2_0;
    globalReadA_0_0_3_0 = A + globalReadOffsetA_0_0_3_0;

    /* global read inc B from base */
    globalReadB_0_0_0_0 = B + globalReadOffsetB_0_0_0_0;
    globalReadB_0_0_1_0 = B + globalReadOffsetB_0_0_1_0;
    globalReadB_0_0_2_0 = B + globalReadOffsetB_0_0_2_0;
    globalReadB_0_0_3_0 = B + globalReadOffsetB_0_0_3_0;

    /* global read A */
    a_0_0_0_0 = *(globalReadA_0_0_0_0 + 0);
    a_0_0_1_0 = *(globalReadA_0_0_1_0 + 0);
    a_0_0_2_0 = *(globalReadA_0_0_2_0 + 0);
    a_0_0_3_0 = *(globalReadA_0_0_3_0 + 0);

    /* global read B */
    b_0_0_0_0 = *(globalReadB_0_0_0_0 + 0);
    b_0_0_1_0 = *(globalReadB_0_0_1_0 + 0);
    b_0_0_2_0 = *(globalReadB_0_0_2_0 + 0);
    b_0_0_3_0 = *(globalReadB_0_0_3_0 + 0);

    psdIter += LOCAL_DEPTHU;

    

    __syncthreads(); //PGR=0, prior iter done reading lds


    /* local write a */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteA_0_0_0_0 + 0) = a_0_0_0_0;
    *(localWriteA_0_0_1_0 + 0) = a_0_0_1_0;
    *(localWriteA_0_0_2_0 + 0) = a_0_0_2_0;
    *(localWriteA_0_0_3_0 + 0) = a_0_0_3_0;
#pragma clang diagnostic pop


    /* local write b */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteB_0_0_0_0 + 0) = b_0_0_0_0;
    *(localWriteB_0_0_1_0 + 0) = b_0_0_1_0;
    *(localWriteB_0_0_2_0 + 0) = b_0_0_2_0;
    *(localWriteB_0_0_3_0 + 0) = b_0_0_3_0;
#pragma clang diagnostic pop


    __syncthreads(); //




    /* iter 0 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 1 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 2 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 3 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 4 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 5 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 6 */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read increment a */
    localReadA += LOCAL_SPLITU*(MT0I+PAD);

    /* local read increment b */
    localReadB += LOCAL_SPLITU*(MT1J+PAD);
    MAC_4x4


    /* iter 7 (localWrite + swap local pointers iteration) */


    /* local read a */
    rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0]; 
    rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0]; 
    rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0]; 
    rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0]; 

    /* local read b */
    rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0]; 
    rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0]; 
    rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0]; 
    rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0]; 

    /* local read init pointers a */
    localReadA = (DATA_TYPE *)(localMemory + localReadOffsetA);

    /* local read init pointers b */
    localReadB = (DATA_TYPE *)(localMemory + localReadOffsetB);
    MAC_4x4




    /******************************************/
    /* Unrolled Loop - End                    */
    /******************************************/

  }
#if 1
  /******************************************/
  /* Tail Loop                              */
  /******************************************/


  /* global read addresses: unroll offsets a */
  unsigned int globalReadOffsetA_0_0 = globalReadOffsetA + 0 + 0*LSCA + psdIter;

  /* global read addresses: unroll offsets b */
  unsigned int globalReadOffsetB_0_0 = globalReadOffsetB + 0 + 0*LSCB + psdIter;

  unsigned int tmpBits = 0;
  tmpBits = MAGIC_DIV2((globalReadOffsetA_0_0), magicStructL);
  unsigned int globalReadOffsetAL_0_0 = (globalReadOffsetA_0_0) - tmpBits*numIterL;
  unsigned int psdPackedBits = 0;
  psdPackedBits = tmpBits;

  unsigned int globalReadOffsetAK_0_0 = psdPackedBits;

  tmpBits = MAGIC_DIV2((globalReadOffsetB_0_0), magicStructL);
  unsigned int globalReadOffsetBL_0_0 = (globalReadOffsetB_0_0) - tmpBits*numIterL;
  psdPackedBits = tmpBits;
  unsigned int globalReadOffsetBK_0_0 = psdPackedBits;

  /* global read addresses: final offsets a */
  int64_t globalReadOffsetA_0_0_0_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_0_0), (globalReadOffsetAK_0_0) );
  int64_t globalReadOffsetA_0_0_1_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_1_0), (globalReadOffsetAK_0_0) );
  int64_t globalReadOffsetA_0_0_2_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_2_0), (globalReadOffsetAK_0_0) );
  int64_t globalReadOffsetA_0_0_3_0 = GLOBAL_OFFSET_A( (globalReadOffsetAL_0_0), (globalReadOffsetA0I_3_0), (globalReadOffsetAK_0_0) );

  /* global read addresses: final offsets b */
  int64_t globalReadOffsetB_0_0_0_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_0_0), (globalReadOffsetBK_0_0) );
  int64_t globalReadOffsetB_0_0_1_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_1_0), (globalReadOffsetBK_0_0) );
  int64_t globalReadOffsetB_0_0_2_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_2_0), (globalReadOffsetBK_0_0) );
  int64_t globalReadOffsetB_0_0_3_0 = GLOBAL_OFFSET_B( (globalReadOffsetBL_0_0), (globalReadOffsetB1J_3_0), (globalReadOffsetBK_0_0) );

  /* global read inc A from base */
  globalReadA_0_0_0_0 = A + globalReadOffsetA_0_0_0_0;
  globalReadA_0_0_1_0 = A + globalReadOffsetA_0_0_1_0;
  globalReadA_0_0_2_0 = A + globalReadOffsetA_0_0_2_0;
  globalReadA_0_0_3_0 = A + globalReadOffsetA_0_0_3_0;

  /* global read inc B from base */
  globalReadB_0_0_0_0 = B + globalReadOffsetB_0_0_0_0;
  globalReadB_0_0_1_0 = B + globalReadOffsetB_0_0_1_0;
  globalReadB_0_0_2_0 = B + globalReadOffsetB_0_0_2_0;
  globalReadB_0_0_3_0 = B + globalReadOffsetB_0_0_3_0;


  /* global read A */
  a_0_0_0_0 = ( (globalReadOffsetAL_0_0 + 0) >= (sizeL ) || (globalReadOffsetAK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadA_0_0_0_0 + 0);
  a_0_0_1_0 = ( (globalReadOffsetAL_0_0 + 0) >= (sizeL ) || (globalReadOffsetAK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadA_0_0_1_0 + 0);
  a_0_0_2_0 = ( (globalReadOffsetAL_0_0 + 0) >= (sizeL ) || (globalReadOffsetAK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadA_0_0_2_0 + 0);
  a_0_0_3_0 = ( (globalReadOffsetAL_0_0 + 0) >= (sizeL ) || (globalReadOffsetAK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadA_0_0_3_0 + 0);

  /* global read B */
  b_0_0_0_0 = ( (globalReadOffsetBL_0_0 + 0) >= (sizeL ) || (globalReadOffsetBK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadB_0_0_0_0 + 0);
  b_0_0_1_0 = ( (globalReadOffsetBL_0_0 + 0) >= (sizeL ) || (globalReadOffsetBK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadB_0_0_1_0 + 0);
  b_0_0_2_0 = ( (globalReadOffsetBL_0_0 + 0) >= (sizeL ) || (globalReadOffsetBK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadB_0_0_2_0 + 0);
  b_0_0_3_0 = ( (globalReadOffsetBL_0_0 + 0) >= (sizeL ) || (globalReadOffsetBK_0_0 + 0) >= (sizeK )) ? SCALAR_OOB_DATA : *(globalReadB_0_0_3_0 + 0);


  __syncthreads(); //


  /* local write init pointers A */
  localWriteA_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_0_0);
  localWriteA_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_1_0);
  localWriteA_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_2_0);
  localWriteA_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetA_0_0_3_0);


  /* local write init pointers B */
  localWriteB_0_0_0_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_0_0);
  localWriteB_0_0_1_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_1_0);
  localWriteB_0_0_2_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_2_0);
  localWriteB_0_0_3_0 = (DATA_TYPE *)(localMemory + localWriteOffsetB_0_0_3_0);


  /* local write a */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteA_0_0_0_0 + 0) = a_0_0_0_0;
    *(localWriteA_0_0_1_0 + 0) = a_0_0_1_0;
    *(localWriteA_0_0_2_0 + 0) = a_0_0_2_0;
    *(localWriteA_0_0_3_0 + 0) = a_0_0_3_0;
#pragma clang diagnostic pop


    /* local write b */

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconditional-uninitialized"
    *(localWriteB_0_0_0_0 + 0) = b_0_0_0_0;
    *(localWriteB_0_0_1_0 + 0) = b_0_0_1_0;
    *(localWriteB_0_0_2_0 + 0) = b_0_0_2_0;
    *(localWriteB_0_0_3_0 + 0) = b_0_0_3_0;
#pragma clang diagnostic pop


    __syncthreads(); //


    /* tail loop: macs */

    while ( psdIter < (numIterK*numIterL)) {


      /* local read a */

      rA[0*VECTOR_WIDTH+0] = localReadA[0*SG0I*VECTOR_WIDTH + 0];
      rA[1*VECTOR_WIDTH+0] = localReadA[1*SG0I*VECTOR_WIDTH + 0];
      rA[2*VECTOR_WIDTH+0] = localReadA[2*SG0I*VECTOR_WIDTH + 0];
      rA[3*VECTOR_WIDTH+0] = localReadA[3*SG0I*VECTOR_WIDTH + 0];


      /* local read b */

      rB[0*VECTOR_WIDTH+0] = localReadB[0*SG1J*VECTOR_WIDTH + 0];
      rB[1*VECTOR_WIDTH+0] = localReadB[1*SG1J*VECTOR_WIDTH + 0];
      rB[2*VECTOR_WIDTH+0] = localReadB[2*SG1J*VECTOR_WIDTH + 0];
      rB[3*VECTOR_WIDTH+0] = localReadB[3*SG1J*VECTOR_WIDTH + 0];


      /* local read inc a */

      localReadA += LOCAL_SPLITU*(MT0I+PAD);


      /* local read inc b */

      localReadB += LOCAL_SPLITU*(MT1J+PAD);

      psdIter++;

      MAC_4x4

    }
#endif //tail loop end



  /* not-LocalSplitU: global write indices */

  unsigned int flattenedGlobalC0 = (wg0I)*MT0I + (serial % SG0I)*VECTOR_WIDTH;
  unsigned int flattenedGlobalC1 = (wg1J)*MT1J + (serial / SG0I)*VECTOR_WIDTH;
  unsigned int globalC0I = flattenedGlobalC0;
  unsigned int globalC1J = flattenedGlobalC1;


  /* not-LocalSplitU: global write */


  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 0*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 0*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (0*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 1*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 1*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (1*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 2*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 2*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (2*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  0*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 0*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[0*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  1*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 1*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[1*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  2*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 2*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[2*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }

  /* new vw0 offset - inc and extract tensor dims */
  globalC0I =   flattenedGlobalC0 +  3*SG0I*VECTOR_WIDTH;
  /* new vw1 offset - inc and extract tensor dims */
  globalC1J =   flattenedGlobalC1 + 0 + 3*SG1J*VECTOR_WIDTH;
  if (flattenedGlobalC0 + 3*SG0I*VECTOR_WIDTH < size0I) {  if (flattenedGlobalC1 + 3*SG1J*VECTOR_WIDTH < size1J) {  TYPE_MAC_WRITE( D[ GLOBAL_D( (uint64_t) globalC0I, (uint64_t) globalC1J) ], alpha, rC[3*VECTOR_WIDTH+0 + (3*VECTOR_WIDTH+0)*TT0I]) } }


}

#undef UNROLL
#undef LOCAL_SPLITU
#undef LOCAL_DEPTHU
#undef SG0I
#undef SG1J
#undef TT0I
#undef TT1J
#undef MT0I
#undef MT1J
#undef NLCA
#undef NLCB
#undef NLPA
#undef NLPB
#undef LSCA
#undef LSPA
#undef LSCB
#undef LSPB
#undef GLOBAL_C
#undef GLOBAL_OFFSET_A
#undef GLOBAL_OFFSET_B
#undef DATA_TYPE
#undef DEST_DATA_TYPE
#undef COMPUTE_DATA_TYPE
#undef LDS_OFFSET_B
#undef LDS_OFFSET_BLK
#undef LDS_NUM_ELEMENTS
#undef NUM_THREADS
#undef WORK_GROUP_MAPPING
#undef VECTOR_WIDTH
#undef GLOBAL_LOAD_VECTOR_WIDTH_A
#undef GLOBAL_LOAD_VECTOR_WIDTH_B
#undef GLOBAL_WRITE_VECTOR_WIDTH
#undef MAC
#undef TYPE_MAC
#undef TYPE_MAC_WRITE
#undef GLOBAL_SPLITU
#undef SCALAR_ZERO
#undef SCALAR_OOB_DATA
#undef MAC_4x4
#undef strideD0I
#undef strideC0I
#undef strideAL
#undef strideBL
#undef globalReadOffsetAK
#undef globalReadOffsetBK




